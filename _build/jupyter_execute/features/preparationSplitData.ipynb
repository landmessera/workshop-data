{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datensets erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem ein ersten Eindruck von den Daten verschafft und entschieden wurde, wie mit fehlenden Daten umgegangen wird, folgt nun die Aufsplittung der Daten in einzelne Datensets. \n",
    "\n",
    "**Warum ist eine Aufsplittung notwendig?** \n",
    "\n",
    "Beispiel:\n",
    "Familie Maier lebt mit Katze Felix in einem Haus. Die Katze bringt immer häufiger lebende Beute, meist Mäuse, mit ins Haus. Herr Maier ist ein Tierliebhaber, aber Mäuse möchte er nicht im Haus haben. Er hat eine Idee: Mit einem KI-System möchte er eine **Katzenklappe** entwickeln, **die Katzen nur dann hinein lässt, wenn die Katze keine Beute mitbringt**. Zunächst installiert er eine Kamera, sammelt 1000 Bilder und weist die Bilder manuell 4 Kategorien zu:\n",
    "1. keine Katze (350 Bilder)\n",
    "2. Felix ohne Beute von vorne (300 Bilder)\n",
    "3. Felix ohne Beute von hinten (300 Bilder)\n",
    "4. Felix mit Beute von vorne (50 Bilder)\n",
    "\n",
    "```{figure} ../images/catflap.jpg\n",
    "---\n",
    "height: 350px\n",
    "align: left\n",
    "name: fig-catflap\n",
    "---\n",
    "```\n",
    "<div style=\"font-size: 8px;\">Quelle: Andreas Göllner auf Pixabay</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Standardfall (Kategorien 1-3) soll die Katzenklappe offen sein. Die Bilder der Kategorien 1-3 erhalten das Label \"offen\". Wenn Felix mit einer Beute vor der Katzenklappe steht (Kategorie 4), soll diese verriegelt werden. Die Bilder der Kategorie 4 werden mit dem Label \"gesperrt\" versehen. Herr Maier trainiert ein Machine Learning-Modell mit den 1000 Bildern und entsprechenden Labeln. Anschließend prüft er das trainierte Modell mit ingesamt 80 von den 1000 Bildern (40 mit dem Label \"offen\" und 40 mit dem Label \"gesperrt\"). Alle 80 Bilder werden richtig erkannt. Herr Meier ist begeistert und nimmt das System in Betrieb. Am nächsten Morgen wird Herr Meier von einer Maus in der Küche begrüßt. \n",
    "\n",
    "**Was ist passiert?**\n",
    "\n",
    "Herr Maier hat mit den gleichen Bildern getestet, mit denen er auch das Modell trainiert hat. Das Modell hat die Bilder mit entsprechendem Label bereits gesehen und konnte so mit 100% Genauigkeit, alle Bilder richtig klassifizieren. Neue Bilder, der letzten Nacht, wurden falsch klassifiziert. Das Modell war also noch nicht gut genug, um im Praxiseinsatz den Erwartungen zu entsprechen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Attention}\n",
    "Wichtig: Verwenden Sie nie Daten in der Testphase, die bereits für das Training verwendet wurden.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herr Maier erstellt ein Testdatenset. Hierzu nimmt er neue Bilder auf und weißt manuell die Labels zu. Mit diesen neuen Bildern (50 mit dem Label \"offen\" und 50 mit dem Label \"gesperrt\") wird getestet. Es stellt sich heraus, dass die Erkennungsrate lediglich bei 70% liegt. Eine Erkennungsrate von 70% bedeutet, dass 70 von 100 Bilder richtig erkannt werden. Herr Meier vermutet, dass die Anzahl der Bilder für das Training nicht ausreicht. Es werden weitere 1000 Beispiel-Bilder erstellt. Es liegen jetzt 2000 Bilder folgender Kategorien für das Training vor:\n",
    "\n",
    "1. keine Katze (600 Bilder), Label \"offen\"\n",
    "2. Felix von vorne (600 Bilder), Label \"offen\"\n",
    "3. Felix von hinten (600 Bilder), Label \"offen\"\n",
    "4. Felix mit Beute von vorne (200 Bilder), Label \"gesperrt\"\n",
    "\n",
    "Anschließend testet Herr Maier erneut mit dem erstellten Testdatenset. Das Ergebnis liegt jetzt bei einer Erkennungsrate von 90%. Damit ist Herr Maier zufrieden und nimmt das Modell erneut in Betrieb. Einige Wochen hat Herr Maier Ruhe vor ungewünschten Beutetieren in der Wohnung. Hin und wieder kommt es jedoch vor, dass eine Fehlentscheidung vom System getroffen wird, wie erwartet sind ca. 10% der Klassifikationen fehlerhaft. Herr Maier möchte das Modell weiter verbessern. Dieses Mal versucht er die **Hyperparameter** des Modells anzupassen. Im Gegensatz zu Parameter eines Modells, die während der Trainingsphase gelernt werden, sind Hyperparameter, Parameter, die Einstellungen am Algorithmus selbst erlauben. Im Fall des eingesetzten Neuronalen Netz, experimentiert Herr Maier mit der Netzarchitektur (Anzahl der Hidden Layer und die Lernrate werden variiert). Die Optimierungsversuche werden in mehreren hundert Versuchsläufen angepasst und mit dem Testdatenset getestet. Die Erkennungsrate beträgt nach der Optimierung 97%. Herr Maier ist zufrieden und nimmt das optimierte System in Betrieb. Die Enttäuschung ist groß, als in den folgenden Tagen wieder häufiger Mäuse in der Wohnung sind. \n",
    "\n",
    "**Wie kann es sein, dass die Erkennungsrate von 90% auf 97% gestiegen ist und das Modell wesentlich schlechter im Betrieb abschneidet?**\n",
    "\n",
    "Die Hyperparameter wurden für das Testset optimiert. Es handelt sich in diesem Fall um eine Überanpassung an das Testdatenset, auch **Overfitting** genannt. In jedem der Versuchsläufe wurde das gleiche Testdatenset verwendet und anschließend optimiert. Besser ist es, wenn ein weiteres Datenset erstellt wird, das für Optimierungsversuche der Hyperparameter verwendet wird. Dieses Datenset wird **Validierungsdatenset** genannt. Das Testdatenset wird nach Abschluss der Optimierungen einmalig verwendet um das Modell abschließend zu prüfen. So kann Overfitting rechtzeitig vor in Betrieb nahme erkannt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Attention}\n",
    "Wichtig: Verwenden Sie ein Validierungsset, wenn Sie häufige Optimierungen auf Basis des Testergebnis vornehmen.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings-, Validierungs- und Testdatenset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Entwicklung von Machine Learning Verfahren werden drei Datensets erstellt:\n",
    "* Trainigsdatenset\n",
    "* Validierungsdatenset\n",
    "* Testdatenset\n",
    "\n",
    "Das **Trainingsdatenset** wird zum trainieren des Modells verwendet. Trainieren bedeutet, dass die Parameter des Modells aus Erfahrung (Daten) gelernt wird.\n",
    "\n",
    "Das **Validierungsdatenset** wird verwendet, um das Modell während des Entwicklungsprozesses in mehreren Iterationen zu prüfen. Auf Basis des Ergebnisses werden Optimierungen wie z.B. die Anpassung von Hyperparameter vorgenommen und anschließend erneut mit dem Validierungsset geprüft. \n",
    "\n",
    "Bevor ein Modell in Betrieb genommen werden kann, findet abschließend eine Prüfung mit dem **Testdatenset** statt. Das Ergebnis des Testdatensets sollte nicht verwendet werden, um Optimierungen durchzuführen. Ist das Ergebnis des Validierungsdatensets signifikant besser als das Ergebnis des Trainingsdatensets liegt mit hoher Wahrscheinlichkeit eine Überanpassung (Overfitting) des Modells vor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wissen prüfen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Validierungsdatenset ist notwendig wenn ...\n",
    "\n",
    "```{dropdown} ... sehr wenige Daten vorliegen.\n",
    "<font color='red'>Falsch.</font>\n",
    "```\n",
    "```{dropdown} ... es viele Hyperparameter gibt, die angepasst werden müssen.\n",
    "<font color='green'>Richtig.</font>\n",
    "```\n",
    "```{dropdown} ... ein komplexes Modell gelernt werden soll, also viele Modellparameter gelernt werden müssen.\n",
    "<font color='red'>Falsch.</font>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testdaten dürfen ...\n",
    "\n",
    "```{dropdown} ... für die Optimierung der Hyperparameter und für das Training verwendet werden.\n",
    "<font color='red'>Falsch.</font>\n",
    "```\n",
    "```{dropdown} ... für das Training und das Testen verwendet werden.\n",
    "<font color='red'>Falsch.</font>\n",
    "```\n",
    "```{dropdown} ... ausschließlich für das Testen verwendet werden.\n",
    "<font color='green'>Richtig.</font>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was bedeutet Überanpassung (Overfitting)?\n",
    "\n",
    "```{dropdown} Das Modell ist zu allgemein.\n",
    "<font color='red'>Falsch.</font>\n",
    "```\n",
    "```{dropdown} Das Modell wurde zu sehr für die Trainingsdaten optimiert.\n",
    "<font color='green'>Richtig.</font>\n",
    "```\n",
    "```{dropdown} Das Modell liefert im Betrieb bessere Ergebnisse als in der Testphase.\n",
    "<font color='red'>Falsch.</font>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was sollte bei der Erstellung der Datansets beachtet werden?\n",
    "* Datensets müssen disjunkt sein\n",
    "* Geeignete Größe der Datensets wählen\n",
    "* Datensets sollten wenn möglich balanciert sein\n",
    "* Ähnliche Charakteristiken zu Daten im Betrieb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensets müssen disjunkt sein\n",
    "\n",
    "Wie bereits ausführlich am Beispiel Katzenklappe erläutert, ist es enorm wichtig, dass sich die Datensets nicht überschneiden. Achten Sie besonders darauf, dass die Testdaten niemals zum trainieren des Modells verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../images/datasplitDisjunkt.png\n",
    "---\n",
    "width: 550px\n",
    "align: left\n",
    "name: fig-split-disjunkt\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Note}\n",
    "Nicht disjunkte Datensets kommen in der Praxis häufiger vor als man annimmt. Meist sind es Flüchtigkeitsfehler. Die Auswirkung ist jedoch enorm. \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geeignete Größe der Datensets wählen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wieviel Prozent der Daten sollten als Trainings-, Validierungs- und Testdaten verwendet werden? Wie bei den meisten Entscheidungen im Machine Learning Bereich hängt auch in diesem Fall eine gute Entscheidung vom Anwendungsfall ab. Eine grobe Richtlinie und Empfehlung lautet:\n",
    "* 60% der Daten als Trainingsdaten\n",
    "* 20% der Daten als Validierungsdaten\n",
    "* 20% der Daten als Testdaten\n",
    "\n",
    "\n",
    "```{figure} ../images/datasplitTvtDist.png\n",
    "---\n",
    "height: 150px\n",
    "align: left\n",
    "name: fig-split-dist\n",
    "---\n",
    "```\n",
    "\n",
    "Zum Beispiel kann bei sehr vielen verfügbaren Datensätzen > 100000 eine geringere Validierungs- und Trainingsmenge ausreichen. Eine Mögliche Verteilung kann 90% Training, 5% Validierung, 5% Test lauten. Wichtig ist, dass in den Validierungs- und Testdatensets möglichst alle Varianten enthalten sind und den in der Realität vorkommenden Daten ähnlich sind. Im Fall der Katzenklappen-Anwendung ist es von Bedeutung, dass möglichst unterschiedliche Bilder von den unterschiedlichen Situationen (Katze von vorne, Katze von hinten, keine Katze, Katze mit Beute) und unterschiedliche Belichtungen, wie z.B. in der Dämmerung, Nachts, bei Tag etc. in jedem Datenset enthalten sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensets sollten wenn möglich balanciert sein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was bedeutet in Kontext von Machine Learning \"balancierte Datensets\"?\n",
    "Schauen wir uns noch einmal das Katzenklappen-Beispiel an. Es handelt sich bei diesem Anwendungsfall um eine Klassifikation. Es soll ein Modell gelernt werden, dass als Eingabe ein Bild erhält und als Ausgabe eine der beiden Klassen \"offen\" oder \"gesperrt\" ausgibt. Wobei \"offen\" und \"gesperrt\" die Zustände sind, die aufgrund der Klassifikation erfolgen sollen. Zu Beginn liegen 950 Bilder mit dem Label \"offen\" vor und nur 50 Bilder mit dem Label \"gesperrt\". Es handelt sich in diesem Fall um eine Menge von Daten, die entsprechend der Anzahl der verfügbaren Bilder pro Klasse nicht \"balanciert sind\". \n",
    "\n",
    "```{figure} ../images/datasplitImbalanced.png\n",
    "---\n",
    "width: 350px\n",
    "align: left\n",
    "name: fig-imbalanced\n",
    "---\n",
    "```\n",
    "\n",
    "Ein vollständig balancierte Datenmenge liegt vor, wenn von 1000 verfügbaren Bildern, 500 mit dem Label \"offen\" und 500 mit dem Label \"gesperrt\" versehen sind. Balanciert bedeutet also, es liegt eine Gleichverteilung vor.\n",
    "\n",
    "Balancierte Datensets führen meist zu einem besseren Ergebnis. Zunächst sollte man prüfen ob sich die Datenmenge aus der die Datensets erstellt werden balanciert ist. Handelt es sich um keine balancierte Datenmenge, sollte versucht werden eine balancierte Datenmenge zu erhalten. Wenn genug Daten vorliegen, können Teilmengen ausgewählt werden. Wenn wenig Daten vorliegen, kann eine weitere Datenerhebung sinnvoll sein. Im Fall der Katzenklappen-Anwendung könnte die Anzahl der \"Katze mit Beute\"-Bilder erhöht werden, durch weitere Aufzeichnungen. \n",
    "\n",
    "Nicht balancierte Datensets kommen in der Praxis sehr häufig vor. Lässt sich die Verteilung der Daten nicht ändern, kann mit nicht balancierten Datenset ein Testlauf gestartet werden. Bei der Bewertung des Ergebnisse muss diese Eigenschaft des Datensets berücksichtigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Tip}\n",
    "Achten Sie bei der Aufteilung der Datensets auf die Verteilung der Daten. Erstellen sie wenn möglich Datensets die balanciert sind.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ähnliche Charakteristiken zu Daten im Betrieb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Charakteristiken der Trainings-, Validierungs- und Testdatensets sollten möglichst ähnlich zu den Charakteristiken der Daten im Betrieb sein. Die Verteilung der Anzahl pro Klasse sind eine Charakteristik. Je nach Anwendungsfall gibt es weitere Charakteristiken.\n",
    "\n",
    "**Am Beispiel der Katzenklappe**: Es existieren meherere Bilder mit der gleichen Beute in den Daten. Wenn man die Zuweisung der Datensätze in die jeweiligen Datensets beliebig erstellt, kann es sein, dass Bilder der gleichen Beute im Trainings- als auch im Testset enthalten sind. Das hat zur Folge, dass das Modell die Beute bereits im Training gesehen hat. Die Beute, die Felix in Zukunft mitbringen wird, hat das Modell noch nicht gesehen. Der Unterschied von der Test-Situation und der Realität (im Betrieb), weicht stark ab. Das Ergebnis unter Verwendung der Testdaten wird besser sein, als das Ergebnis im Betrieb.\n",
    "\n",
    "```{figure} ../images/datasplitTimeCatflap.png\n",
    "---\n",
    "width: 650px\n",
    "align: left\n",
    "name: fig-time-catflap\n",
    "---\n",
    "```\n",
    "\n",
    "Lösung: Die Daten werden nicht beliebig gesplittet, sondern nach Aufnahmedatum sortiert und anschließend gesplittet. So wird die Wahrscheinlichkeit, dass ein Beutebild auch im Testset existiert minimiert. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Tip}\n",
    "Denken Sie über das Szenario im Betrieb nach: \n",
    "* Welche Daten stehen dem Modell zum Training zur Verfügung?\n",
    "* Welche Daten werden im Betrieb erzeugt, bzw. als Anfrage an das Modell gestellt? \n",
    "* Wie unterscheiden sich die Daten in Training und Betrieb? \n",
    "* Spiegelt sich diese Unterscheidung auch im Trainings- und Testdatenset wieder?\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel Titanic: Datensets erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Module importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufbereitete Daten laden und anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3    male  22.0      1      0   7.2500        S\n",
       "1           1       1  female  38.0      1      0  71.2833        C\n",
       "2           1       3  female  26.0      0      0   7.9250        S\n",
       "3           1       1  female  35.0      1      0  53.1000        S\n",
       "4           0       3    male  35.0      0      0   8.0500        S\n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...\n",
       "886         0       2    male  27.0      0      0  13.0000        S\n",
       "887         1       1  female  19.0      0      0  30.0000        S\n",
       "888         0       3  female  28.0      1      2  23.4500        S\n",
       "889         1       1    male  26.0      0      0  30.0000        C\n",
       "890         0       3    male  32.0      0      0   7.7500        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../output/titanic/preparedData.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sind die Daten ungleich verteilt in Bezug auf die Anzahl der Klassen? Prüfen durch Anzeigen der Verteilung mit Hilfe der [hist()-Methode](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbe2d321710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Users/alandmesser/git/books/workshop-data/_build/jupyter_execute/features/preparationSplitData_30_1.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Survived'].hist(legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Klasse \"Überlebt\" (Survived=1) enthält 342 Datensätze und die Klasse \"Nicht Überlebt\" (Survived=0) enthält 549 Datensätze. Es handelt sich nicht um ein balanciertes Datenset, jedoch sind einige Datensätze in der Klasse \"Überlebt\" vorhanden. Der Unterschied von 207 Datensätzen bei einer Gesamtzahl von 891 Datensätzen ist akzeptabel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereitung für die Erstellung der Datensets mit Scikit-Learn:\n",
    "1. Einen Pandas Dataframe erstellen der die Merkmale enthält\n",
    "2. Eine Pandas Dataframe (Series) erstellen der die Labels enthält"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Enternen der Label-Spalte \"Survived\" um ein Pandas Datenframe zu erhalten, der nur die Merkmale enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         3    male  22.0      1      0   7.2500        S\n",
       "1         1  female  38.0      1      0  71.2833        C\n",
       "2         3  female  26.0      0      0   7.9250        S\n",
       "3         1  female  35.0      1      0  53.1000        S\n",
       "4         3    male  35.0      0      0   8.0500        S\n",
       "..      ...     ...   ...    ...    ...      ...      ...\n",
       "886       2    male  27.0      0      0  13.0000        S\n",
       "887       1  female  19.0      0      0  30.0000        S\n",
       "888       3  female  28.0      1      2  23.4500        S\n",
       "889       1    male  26.0      0      0  30.0000        C\n",
       "890       3    male  32.0      0      0   7.7500        Q\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Erstellen eines Pandas Dataframe Series durch Auswahl der Label-Spalte \"Survived\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Survived']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estellen der Datensets unter Verwendung der [train_test_split()-Methode von Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Ziel ist es, die Daten in 80% Trainingsdaten, 20% Validierungsdaten und 20% Testdaten zu teilen. Das erfolgt mit der train_test_split()-Methode in zwei Schritten:\n",
    "1. Die Daten werden im Verhältnis 80:20 gesplittet. 80% der Daten werden als Trainingsdaten bezeichnet, 20% der Daten als Testdaten. \n",
    "2. Die Trainingsdaten werden nochmals geteilt. 75% werden weiterhin als Trainingsdaten verwendet, 25% als Validierungsdaten.\n",
    "\n",
    "Der Parameter **random_state** wird auf einen beliebigen Wert (hier 1) festgelegt. Wird für diesen Parameter ein Wert gesetzt, erhält man bei jeder Ausführung des Codes die gleiche Aufteilung. Konkret bedeutet das, wenn der erste Datensatz bei einer Ausführung des Codes dem Testdatensatz zugewiesen wird, ist das auch bei der zweiten Ausführung der Fall. Diese Einstellung wird verwendet um das Ergebnis reproduzieren zu können.\n",
    "\n",
    "Dem Parameter **stratify** werden die Labels übergeben. Damit wird sichergestellt, dass die Datensets die gleiche Verteilung in Bezug auf die Klassen enthalten. In diesem Fall sind es 0.61% der Daten mit dem Label \"nicht überlebt\" und 0.39% der Daten mit dem Label \"überlebt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainingsdatenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train  (534, 7)\n",
      "Shape of y_train  (534,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train ',X_train.shape)\n",
    "print('Shape of y_train ',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validierungsdatenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_val  (178, 7)\n",
      "Shape of y_val  (178,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_val ',X_val.shape)\n",
    "print('Shape of y_val ',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testdatenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test  (179, 7)\n",
      "Shape of y_test  (179,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_test ',X_test.shape)\n",
    "print('Shape of y_test ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verteilung der Klassen im Trainingsdatenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616105\n",
       "1    0.383895\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verteilung der Klassen im Validierungsdatenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.617978\n",
       "1    0.382022\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verteilung der Klassen im Testdatenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.614525\n",
       "1    0.385475\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensets speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datensets werden in einem Python Dictionary abgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_val': X_val,\n",
    "    'y_val': y_val,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/titanic/datasets_or.pkl', 'wb') as handle:\n",
    "    pickle.dump(datasets, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[234, 206, 292, 265, 261, 247, 252, 204, 217, 220]\n",
      "[253, 215, 204]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(52)\n",
    "\n",
    "# Sex\n",
    "sex_values = ['female', 'male']\n",
    "\n",
    "# Pclass\n",
    "pclass_values = [1, 2, 3]\n",
    "\n",
    "# Embarked\n",
    "embarked_values = ['Q','S','C']\n",
    "# Survived\n",
    "survived_values = [0,1]\n",
    "\n",
    "outlier_xtrain_count = int(datasets['X_train'].shape[0]*0.02)\n",
    "outlier_xval_count = int(datasets['X_val'].shape[0]*0.02)\n",
    "outlier_xtest_count = int(datasets['X_test'].shape[0]*0.02)\n",
    "\n",
    "outlier = {\n",
    "    'X_train': {\n",
    "        'age': random.sample(range(200,300), outlier_xtrain_count),\n",
    "        'parch': random.sample(range(20,40), outlier_xtrain_count),\n",
    "        'sibsp': random.sample(range(21,50), outlier_xtrain_count),\n",
    "        'fare': [2630]*outlier_xtrain_count\n",
    "    },\n",
    "    'X_val': {\n",
    "        'age': random.sample(range(200,300), outlier_xval_count),\n",
    "        'parch': random.sample(range(20,40), outlier_xval_count),\n",
    "        'sibsp': random.sample(range(21,50), outlier_xval_count),\n",
    "        'fare': [2630]*outlier_xval_count\n",
    "    },\n",
    "    'X_test': {\n",
    "        'age': random.sample(range(200,300), outlier_xtest_count),\n",
    "        'parch': random.sample(range(20,40), outlier_xtest_count),\n",
    "        'sibsp': random.sample(range(21,50), outlier_xtest_count),\n",
    "        'fare': [2630]*outlier_xtest_count\n",
    "    }\n",
    "}\n",
    "\n",
    "print(outlier['X_train']['age'])\n",
    "print(outlier['X_val']['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (534, 7)\n",
      "y_train (534,)\n",
      "X_val (178, 7)\n",
      "y_val (178,)\n",
      "X_test (179, 7)\n",
      "y_test (179,)\n"
     ]
    }
   ],
   "source": [
    "for key, dataset in datasets.items():\n",
    "    print(key, dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for key, dataset in datasets.items():\n",
    "    y_train_new = []\n",
    "    if 'X' in key:\n",
    "        for (age, sibsp, parch, fare) in zip(outlier[key]['age'], outlier[key]['sibsp'], outlier[key]['parch'], outlier[key]['fare']):\n",
    "            dataset = dataset.append(\n",
    "                {\n",
    "                    'Sex': random.choice(sex_values),\n",
    "                    'Pclass': random.choice(pclass_values),\n",
    "                    'Age': age,\n",
    "                    'Parch': parch,\n",
    "                    'SibSp': sibsp,\n",
    "                    'Fare': fare,\n",
    "                    'Embarked': random.choice(embarked_values)\n",
    "                }, ignore_index=True\n",
    "            )\n",
    "            y_train_new.append(random.choice(survived_values))\n",
    "\n",
    "        y_set = 'y_'+key.split('_')[1]\n",
    "        datasets[y_set] = datasets[y_set].append(pd.Series(y_train_new))\n",
    "        datasets[key] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (544, 7)\n",
      "y_train (544,)\n",
      "X_val (181, 7)\n",
      "y_val (181,)\n",
      "X_test (182, 7)\n",
      "y_test (182,)\n"
     ]
    }
   ],
   "source": [
    "for key, dataset in datasets.items():\n",
    "    print(key, dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Pickle Modul ermöglicht eine einfache und effiziente Speicherung der Daten. Im Vergleich zu anderen Formaten wie z.B. dem Excel-Format, lassen sich Pickle Formate schneller speichern und auslesen. Das Speichern des Python Dictionary erfolgt über folgende zwei Zeilen Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/titanic/datasets.pkl', 'wb') as handle:\n",
    "    pickle.dump(datasets, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über folgende Befehle lässt sich das Dictionary wieder auslesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/titanic/datasets.pkl', 'rb') as handle:\n",
    "    datasets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe der Merkmale des Trainingsdatenset erfolgt über den Key \"X_train\" des eingelesenen Dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3  female  28.0      1      0  24.1500        Q\n",
       "1       3    male  21.0      0      0   7.7958        S\n",
       "2       1    male  54.0      0      0  51.8625        S\n",
       "3       2    male  34.0      1      0  21.0000        S\n",
       "4       1  female  19.0      1      0  91.0792        C"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['X_train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datensets sind erstellt und gespeichert. Vertiefen Sie jetzt zum Abschluss von Teil 1 das Vorgehen am Beispiel des Datenset Bike Buyers anhand der Übungsaufgaben."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}