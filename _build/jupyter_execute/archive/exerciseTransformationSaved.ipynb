{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung: Tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell",
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from sklearn) (0.24.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packete importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerische Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Einlesen der Datensets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesen Sie die gespeicherte Datensets aus der pickle-Datei '../output/bikebuyers/datasets.pkl' aus und geben Sie die ersten fünf Zeilen der Merkmale im Trainingsdatenset (X_train) aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 928\r\n",
      "drwxr-xr-x  6 alandmesser  staff     192 16 Jun 11:04 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  6 alandmesser  staff     192 31 Mär 14:59 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 alandmesser  staff   87182 31 Mär 14:59 bike_buyers.csv\r\n",
      "-rw-r--r--  1 alandmesser  staff   86348 31 Mär 14:59 bike_buyers_clean.csv\r\n",
      "-rw-r--r--  1 alandmesser  staff   84286 11 Jun 16:06 datasets.pkl\r\n",
      "-rw-r--r--  1 alandmesser  staff  163174 15 Jun 11:10 pipeline.pkl\r\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__cinit__() takes at least 2 positional arguments (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2bf46c5615f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/bikebuyers/datasets.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/workshops/lib/python3.7/site-packages/pandas/_libs/internals.pyx\u001b[0m in \u001b[0;36mpandas._libs.internals.BlockManager.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __cinit__() takes at least 2 positional arguments (0 given)"
     ]
    }
   ],
   "source": [
    "!ls -la ../data/bikebuyers/\n",
    "\n",
    "f = open('../data/bikebuyers/datasets.pkl', 'rb')\n",
    "datasets = pickle.load(f)\n",
    "\n",
    "datasets['X_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geben Sie die ersten fünf Zeilen der Zielgrößen im Trainingsdatenset (y_train) aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 1\n",
    "\n",
    "  ```{code-block} python\n",
    "    # Erste Code-Zelle\n",
    "    with open('../data/bikebuyers/datasets.pkl', 'rb') as handle:\n",
    "        datasets = pickle.load(handle)\n",
    "        \n",
    "    datasets['X_train'].head()\n",
    "    \n",
    "    # Zweite Code-Zelle\n",
    "    datasets['y_train'].head()\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Ausreißer erkennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermitteln Sie mit der IQR-Methode die Ausreißer, ersetzen diese mit dem NaN-Wert (np.nan) und geben Sie die Anzahl der Ausreißer pro Merkmal aus. Verwenden Sie den Faktor 1.5 bei der IQR-Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ersetzen Sie die NaN-Werte mit dem Mittelwert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Tip}\n",
    "Schritte zur Lösung:\n",
    "* Eine Variable factor erstellen und mit dem Wert 1.5 belegen.\n",
    "* Mit Hilfe der [quantile()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html)-Methode das 25%-Quantil bestimmen und in einer Variable q1 speichern.\n",
    "* Mit Hilfe der [quantile()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html)-Methode das 75%-Quantil bestimmen und in einer Variable q3 speichern.\n",
    "* Die Differenz von q3 und q1 berechnen und in einer Variable namens iqr speichern.\n",
    "* Die Untere Grenze berechnen durch die Differenz von q1 und dem Faktor multipliziert mit iqr.\n",
    "* Alle Werte die außerhalb des Bereichs liegen (definierte Grenzen) mit dem NaN-Wert belegen.\n",
    "* Mit Hilfe der Methode [isna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html) alle NaN-Werte identifizieren und mit Hilfe der Methode sum() die Anzahl pro Merkmal ausgeben.\n",
    "* Die Methode [fillna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) hilft bei dem Ersetzen der NaN-Werte.\n",
    "* Die [mean()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.mean.html)-Methode ermittelt Mittelwerte eines DataFrames.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 2\n",
    "\n",
    "  ```{code-block} python\n",
    "    # Erste Code-Zelle\n",
    "    X_ = pd.DataFrame(datasets['X_train'])\n",
    "    factor = 1.5\n",
    "    q1 = X_.quantile(0.25)\n",
    "    q3 = X_.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (factor * iqr)\n",
    "    upper_bound = q3 + (factor * iqr)\n",
    "    X_[((X_ < lower_bound) | (X_ > upper_bound))] = np.nan\n",
    "    X_.isna().sum()\n",
    "    \n",
    "    # Zweite‚ Code-Zelle\n",
    "    X_.fillna(X_.mean(), inplace=True)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Outlier Remover Transformer erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Klasse \"OutlierRemoverExtended\", welche das Transformer-Interface von Scikit Learn abbildet und von den Klassen BaseEstimator und TranformerMixin ableitet. Bei der Instanziierung der Klasse sollen zwei Parameter gesetzt werden können:\n",
    "* factor, Default-Wert 1.5\n",
    "* strategy, Default-Wert 'median'\n",
    "\n",
    "Die fit()-Methode soll zwei numpy-Arrays als Parameter (X und y), keine Funktion enthalten und nur die Instanz selbst zurückgeben. Die Transformer-Methode soll die gleichen Parameter wie die fit()-Methode erhalten, Ausreißer mit der IQR-Methode unter Verwendung des factor-Paramters erkennen und mit dem Mittelwert oder dem Median ersetzen. Welche Art zum Einsatz kommt, wird mit dem Paramter strategy bestimmt. Valide Werte sind 'median' und 'mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 3\n",
    "\n",
    "  ```{code-block} python\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    class OutlierRemoverExtended(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, factor=1.5, strategy='median'):\n",
    "            self.factor = factor\n",
    "            self.strategy = strategy\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X, y=None):\n",
    "            X_ = pd.DataFrame(X)\n",
    "            q1 = X_.quantile(0.25)\n",
    "            q3 = X_.quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - (self.factor * iqr)\n",
    "            upper_bound = q3 + (self.factor * iqr)\n",
    "            X_[((X_ < lower_bound) | (X_ > upper_bound))] = np.nan\n",
    "\n",
    "            if self.strategy == 'median':\n",
    "                X_.fillna(X_.median(), inplace=True)\n",
    "            elif self.strategy == 'mean':\n",
    "                X_.fillna(X_.mean(), inplace=True)\n",
    "            else:\n",
    "                raise ValueError('Invalid value for strategy paramter. Valid values are median or mean.')\n",
    "\n",
    "            return X_.values\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Transformer anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Erstellen Sie eine Insatnz der Klasse OutlierRemoverExtended.\n",
    "* Wenden sie die fit_transform()-Methode auf das Trainingsdatenset an und speichern das Ergebnis in einer Variable.\n",
    "* Erstellen Sie ein Pandas DataFrame, übergeben sie dabei die transformierten Werte und geben das Ergebnis aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 4\n",
    "\n",
    "  ```{code-block} python\n",
    "    outlier_remover = OutlierRemoverExtended()\n",
    "    res = outlier_remover.fit_transform(datasets['X_train'])\n",
    "    pd.DataFrame(res)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Pipeline für numerische Daten erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Pipeline mit Hilfe der [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)-Klasse von Scikit Learn. Schritte der Pipeline:\n",
    "1. Der OutlierRemoverExtended-Transformer aus Task 3  \n",
    "2. [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) von Scikit Learn\n",
    "\n",
    "Speichern Sie die Pipeline in einer Variable namens pipeline_numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 5\n",
    "\n",
    "  ```{code-block} python\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    pipeline_numerical = Pipeline(steps=[\n",
    "        ('outlier_remover', OutlierRemoverExtended()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kategorische Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Pipeline für kategorische Daten erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Pipeline mit Hilfe der [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)-Klasse von Scikit Learn. Schritte der Pipeline:\n",
    "1. [OneHot-Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) von Scikit Learn  \n",
    "\n",
    "Speichern Sie die Pipeline in einer Variable namens pipeline_categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 6\n",
    "\n",
    "  ```{code-block} python\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    pipeline_categorical = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformationen koordinieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Pipelines zusammenfügen und Merkmale zuweisen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bezeichnungen der numerischen Features in einer Liste mit Elementen vom Typ String namens 'features_numerical' speichern.\n",
    "* Bezeichnungen der kategorischen Features in einer Liste mit Elmenten vom Typ String namens 'features_categorical' speichern.\n",
    "* Eine Instanz des [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) aus Scikit Learn erstellen. Dabei dem Parameter transformers die Tuples \n",
    "    * ('num', pipeline_numerical, features_numerical)\n",
    "    * ('cat', pipeline_categorical, features_categorical)  \n",
    "übergeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 7\n",
    "\n",
    "  ```{code-block} python\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "    features_categorical = [\n",
    "        'Marital Status', \n",
    "        'Gender', \n",
    "        'Education', \n",
    "        'Occupation', \n",
    "        'Home Owner', \n",
    "        'Commute Distance',\n",
    "        'Region'\n",
    "    ]\n",
    "\n",
    "    transformer_pipeline = ColumnTransformer(\n",
    "        transformers = [\n",
    "            (\n",
    "                'num', \n",
    "                pipeline_numerical,\n",
    "                features_numerical\n",
    "            ),\n",
    "            (\n",
    "                'cat', \n",
    "                pipeline_categorical,\n",
    "                features_categorical\n",
    "            )\n",
    "        ])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Transformer-Pipeline anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die Transformer Pipeline auf dem Trainingsdatenset(X_train) anwenden durch aufrufen der Methode fit_transform() und speichern des Rückgabewert vom Typ Numpy-Array in einer Variable namens 'res'.\n",
    "* Aus dem Numpy-Array res ein Pandas DataFrame erstellen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 8\n",
    "\n",
    "  ```{code-block} python\n",
    "    res = transformer_pipeline.fit_transform(datasets['X_train'])\n",
    "    pd.DataFrame(res)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Merkmalsbezeichnungen hinzufügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die neuen Feature-Bezeichnungen aus der Transformer Pipeline des Step 'onehot' über die Methode [get_feature_names()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) abfragen und in einer Variable namens feature_categorical_onehot speichern.\n",
    "* Aus dem Numpy-Array res und den Merkmalsbezeichnungen (feature_catgorical_onehot und features_numerical) ein Pandas DataFrame erstellen und ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 9\n",
    "\n",
    "  ```{code-block} python\n",
    "    feature_categorical_onehot = transformer_pipeline\\\n",
    "        .transformers_[1][1]['onehot']\\\n",
    "        .get_feature_names(features_categorical)\n",
    "        \n",
    "    pd.DataFrame(res, columns=features_numerical+list(feature_categorical_onehot))\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Auf alle Datensets anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenden Sie die Transformationen auf alle Datensets (Training, Validierung und Test) an und speichern das Ergebnis in den Variablen X_train_transformed, X_val_transformed und X_test_transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie aus jedem transformierten Datenset ein Pandas Datenframe inklusive der Spaltenbezeichnungen und speichern diese in den gleichen Variablen. Die neuen Spaltenbezeichungen der kategorischen Daten können sie aus der Variable feature_categorical_onehot des vorherigen Tasks auslesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geben Sie die ersten Zeilen des Pandas Dataframe X_train_transformed aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 10\n",
    "\n",
    "  ```{code-block} python\n",
    "    # Erste Code-Zelle\n",
    "    X_train_transformed = transformer_pipeline.fit_transform(datasets['X_train'])\n",
    "    X_val_transformed = transformer_pipeline.transform(datasets['X_val'])\n",
    "    X_test_transformed = transformer_pipeline.transform(datasets['X_test'])\n",
    "    \n",
    "    # Zweite Code-Zelle\n",
    "    X_train_transformed = pd.DataFrame(X_train_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "    X_val_transformed = pd.DataFrame(X_val_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "    X_test_transformed = pd.DataFrame(X_test_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "    \n",
    "    # Dritte Code-Zelle\n",
    "    X_train_transformed.head()\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11: Pipeline mit Klassifikator erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie die finale Pipeline, bestehend aus der Transformer Pipeline und anschließendem Predictor in Form eines K-Nearest-Neighbor Klassifikator. Speichern Sie die Pipeline in einer Variable namens 'full_pipeline'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 11\n",
    "\n",
    "  ```{code-block} python\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('transformers', transformer_pipeline),\n",
    "        ('predictor', KNeighborsClassifier(n_neighbors=2))\n",
    "    ])\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: Pipeline verwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trainieren Sie die Pipeline mit dem Trainingsdatenset durch aufrufen der fit()-Methode. \n",
    "* Evaluieren Sie das Modell mit dem Validierungsdatenset durch aufrufen der score()-Methode.\n",
    "\n",
    "Welches Ergebnis erhalten Sie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 12\n",
    "\n",
    "  ```{code-block} python\n",
    "    full_pipeline.fit(datasets['X_train'], datasets['y_train'])\n",
    "    full_pipeline.score(datasets['X_val'], datasets['y_val'])\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13: Grid Search vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Instanz der Klasse [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) aus Scikit Learn. Verwenden folgende Paramter-Einstellungen:\n",
    "* estimator:full_pipeline\n",
    "* param_grid: \n",
    "    * factor values [1.0, 1.5, 2.0, 3.0]\n",
    "    * n_neighbors: [2,3,4,5,6]\n",
    "* cv: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 12\n",
    "\n",
    "  ```{code-block} python\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    param_grid = {\n",
    "        'transformers__num__outlier_remover__factor': [1.0, 1.5, 2.0, 3.0],\n",
    "        'predictor__n_neighbors': [2,3,4,5,6],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(full_pipeline, param_grid, cv=10)\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13: Grid Search anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rufen Sie die fit-Methode unter Verwendung der Trainingsdatensets auf.\n",
    "* Geben Sie die beste Parameterkombination aus.\n",
    "* Geben Sie das Ergebnis der besten Parameterkombination aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 13\n",
    "\n",
    "  ```{code-block} python\n",
    "    grid_search.fit(datasets['X_train'], datasets['y_train'])\n",
    "\n",
    "    print(\"Best params:\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    print(\"Ergebnis mit der besten Parametereinstellung auf den Trainingsdaten:\")\n",
    "    print(f\"{grid_search.best_score_:.3f}\")\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14: Beste Pipeline speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern Sie die Pipeline mit der besten Parametereinstellung in einer Pickle-Datei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 14\n",
    "\n",
    "  ```{code-block} python\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    with open('../output/bikebuyers/pipeline.pkl', 'wb') as handle:\n",
    "            pickle.dump(best_pipeline, handle)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load data\n",
    "with open('../output/bikebuyers/datasets.pkl', 'rb') as handle:\n",
    "    datasets = pickle.load(handle)\n",
    "\n",
    "# Create custom transformer\n",
    "class OutlierRemoverExtended(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5, strategy='median'):\n",
    "        self.factor = factor\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_ = pd.DataFrame(X)\n",
    "        q1 = X_.quantile(0.25)\n",
    "        q3 = X_.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (self.factor * iqr)\n",
    "        upper_bound = q3 + (self.factor * iqr)\n",
    "        X_[((X_ < lower_bound) | (X_ > upper_bound))] = np.nan\n",
    "\n",
    "        if self.strategy == 'median':\n",
    "            X_.fillna(X_.median(), inplace=True)\n",
    "        elif self.strategy == 'mean':\n",
    "            X_.fillna(X_.mean(), inplace=True)\n",
    "        else:\n",
    "            raise ValueError('Invalid value for strategy paramter. Valid values are median or mean.')\n",
    "\n",
    "        return X_.values\n",
    "\n",
    "# Numerical Pipeline\n",
    "pipeline_numerical = Pipeline(steps=[\n",
    "    ('outlier_remover', OutlierRemoverExtended()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical Pipeline\n",
    "pipeline_categorical = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Column Transformer\n",
    "features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "features_categorical = [\n",
    "    'Marital Status', \n",
    "    'Gender', \n",
    "    'Education', \n",
    "    'Occupation', \n",
    "    'Home Owner', \n",
    "    'Commute Distance',\n",
    "    'Region'\n",
    "]\n",
    "\n",
    "transformer_pipeline = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\n",
    "            'num', \n",
    "            pipeline_numerical,\n",
    "            features_numerical\n",
    "        ),\n",
    "        (\n",
    "            'cat', \n",
    "            pipeline_categorical,\n",
    "            features_categorical\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# transform datsets\n",
    "X_train_transformed = transformer_pipeline.fit_transform(datasets['X_train'])\n",
    "X_val_transformed = transformer_pipeline.transform(datasets['X_val'])\n",
    "X_test_transformed = transformer_pipeline.transform(datasets['X_test'])\n",
    "\n",
    "feature_categorical_onehot = transformer_pipeline\\\n",
    "    .transformers_[1][1]['onehot']\\\n",
    "    .get_feature_names(features_categorical)\n",
    "\n",
    "# Zweite Code-Zelle\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "X_val_transformed = pd.DataFrame(X_val_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "\n",
    "print(X_train_transformed.head())\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('transformers', transformer_pipeline),\n",
    "    ('predictor', KNeighborsClassifier(n_neighbors=2))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'transformers__num__outlier_remover__factor': [1.0, 1.5, 2.0, 3.0],\n",
    "    'predictor__n_neighbors': [2,3,4,5,6],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=10)\n",
    "grid_search.fit(datasets['X_train'], datasets['y_train'])\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"Ergebnis mit der besten Parametereinstellung auf den Trainingsdaten:\")\n",
    "print(f\"{grid_search.best_score_:.3f}\")\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "with open('../output/bikebuyers/pipeline.pkl', 'wb') as handle:\n",
    "        pickle.dump(best_pipeline, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}