{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline definieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Erstellung einer Baseline wird ein Klassifikator für die Klassifikationsaufgabe des Beispiel Titanic erstellt, mit dem transformierten Trainingsdatenset trainiert und dem transformierten Validierungsdatenset validiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pakete importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformierte Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/titanic/datasets_transformed.pkl', 'rb') as handle:\n",
    "    datasets_transformed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikator erstellen\n",
    "\n",
    "Als Klassifikator wird ein Entscheidungsbaum verwendet. Scikit-learn liefert den DecisionTreeClassifier. Es handelt sich um einen Prädiktor. Die fit()-Methode wird mit den transformierten Trainingsdaten aufgerufen, um den Entscheidungsbaum zu erstellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier.fit(datasets_transformed['X_train'], datasets_transformed['y_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über den Aufruf der score()-Methode erhält man den Accuracy-Score des Validierungsdatensets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513812154696132"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(datasets_transformed['X_val'], datasets_transformed['y_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das übliche Vorgehen beim Machine Learning ist **experimentell**. Man entwickelt zunächst eine Variante und erhält ein Ergebnis. In unserem Fall ein Accuracy-Score von 0.75. Das bedeutet 75% der vorhergesagten Werte sind richtig. Dieser Score dient als Basis für weitere Optimierungen. Es werden Veränderungen unterschiedlichster Art vorgenommen wie zum Beispiel \n",
    "* Anwendung weiterer Transformationsschritte\n",
    "* Entfernen von Transformationsschritte\n",
    "* Änderung der Transformationseinstellungen\n",
    "* Hinzufügen von Merkmalen\n",
    "* Entfernen von Merkmalen\n",
    "* Modifizieren von Merkmalen\n",
    "* Ändern des Machine Learning Algorithmus \n",
    "* Ändern der Hyperparameter\n",
    "\n",
    "Nach **jeder Änderung** wird **geprüft** ob sich das Ergebnis, der Score, **verbessert oder verschlechtert** hat und entsprechend die Änderung beibehalten oder verworfen. Häufig sind es sehr viele Experimente die durchgeführt werden müssen. Es fällt schwer den Überblick zu behalten und es ist aufwendig die Experimente manuell durchzuführen. Bei der Variation von Hyperparameter kann die sogenannte **Grid-Search**[^footnote3] eingesetzt werden um die Experimente zu automatisieren. Für jeden Hyperparameter wird eine begrenzte Menge von möglichen Werten bestimmt, die getestet werden soll. Grid-Search **testet alle Kombinationen und gibt die Wertekombination des besten Ergebnisses aus**.\n",
    "\n",
    "Wie bereits zu Beginn dieses Abschnitts erwähnt, ist es möglich am Ende der Pipeline statt eines Transformer einen beliebigen Estimator einzusetzen. Ein beliebiger Estimator kann auch ein Prediktor sein. So kann beim Anwendungsbeispiel Titanic einfach der Klassifikator am Ende der Pipeline eingefügt werden. Einer der Vorteile, wenn man die Vorverarbeitungsschritte und den Prediktor in einer Pipeline integriert ist, dass **Grid-Search auch für die Vorverarbeitungsschritte** eingesetzt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikator in Pipeline integrieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellt wird eine Pipeline, die im ersten Schritt die bereits erstellte Transformer-Pipeline enthält und im Anschluss den Klassifikator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../images/pipelineFull.png\n",
    "---\n",
    "height: 180px\n",
    "align: center\n",
    "name: fig-pipelineFull\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer Pipeline laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/titanic/transformer_pipeline.pkl', 'rb') as handle:\n",
    "    transformer_pipeline = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datensets laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/titanic/datasets.pkl', 'rb') as handle:\n",
    "    datasets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(steps=[\n",
    "    ('transformers', transformer_pipeline),\n",
    "    ('predictor', DecisionTreeClassifier(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Pipeline wird mit dem Trainingsdatenset trainiert und dem Validierungsset validiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513812154696132"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(datasets['X_train'], datasets['y_train'])\n",
    "full_pipeline.score(datasets['X_val'], datasets['y_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis ist wie erwartet unverändert. Die Accuracy beträgt 0.75. Nun können mit der Grid Search Methode optimale Einstellungen gefunden werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
