{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übung: Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell",
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pakete importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen der Datensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensets geladen\n"
     ]
    }
   ],
   "source": [
    "with open('../output/bikebuyers/datasets.pkl', 'rb') as handle:\n",
    "    datasets = pickle.load(handle)\n",
    "    \n",
    "print('Datensets geladen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Transformer Pipeline laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesen Sie die gespeicherte Transformer Pipeline aus der pickle-Datei '../output/bikebuyers/transformer_pipeline.pkl' und speichern die Pipeline in einer Variable namens transformer_pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 1\n",
    "\n",
    "  ```{code-block} python\n",
    "  with open('../output/bikebuyers/transformer_pipeline.pkl', 'rb') as handle:\n",
    "    transformer_pipeline = pickle.load(handle)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Pipeline mit Klassifikator erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie die finale Pipeline, bestehend aus der Transformer Pipeline und anschließendem Predictor in Form eines Entscheidungsbaum-Klassifikator. Verwenden Sie hierzu den [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) von Scikit-learn. Belegen Sie den random_state Parameter mit 0 und verwenden sonst die Standard-Einstellungen. Speichern Sie die Pipeline in einer Variable namens 'full_pipeline'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 2\n",
    "\n",
    "  ```{code-block} python\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  full_pipeline = Pipeline(steps=[\n",
    "    ('transformers', transformer_pipeline),\n",
    "    ('predictor', DecisionTreeClassifier(random_state=0))\n",
    "  ])\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Pipeline verwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trainieren Sie die Pipeline mit dem Trainingsdatenset durch aufrufen der fit()-Methode. \n",
    "* Evaluieren Sie das Modell mit dem Validierungsdatenset durch aufrufen der score()-Methode.\n",
    "\n",
    "Welches Ergebnis erhalten Sie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 3\n",
    "\n",
    "  ```{code-block} python\n",
    "  full_pipeline.fit(datasets['X_train'], datasets['y_train'])\n",
    "  full_pipeline.score(datasets['X_val'], datasets['y_val'])\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter optimieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Grid Search vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Instanz der Klasse [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) aus Scikit Learn. Verwenden Sie folgende Paramter-Einstellungen:\n",
    "* estimator:full_pipeline\n",
    "* param_grid: \n",
    "    * factor-Werte: [1.0, 1.5, 2.0, 3.0]\n",
    "    * min_samples_split-Werte: [2,3,4,5,6]\n",
    "* cv: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 4\n",
    "\n",
    "  ```{code-block} python\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "  param_grid = {\n",
    "    'transformers__num__outlier_remover__factor': [1.0, 1.5, 2.0, 3.0],\n",
    "    'predictor__min_samples_split': [2,3,4,5,6]\n",
    "  }\n",
    "\n",
    "  grid_search = GridSearchCV(full_pipeline, param_grid, cv=10)\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Grid Search anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rufen Sie die fit()-Methode unter Verwendung der Trainingsdatensets auf.\n",
    "* Geben Sie die beste Parameterkombination aus.\n",
    "* Geben Sie das Ergebnis der besten Parameterkombination aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 5\n",
    "\n",
    "  ```{code-block} python\n",
    "  print(\"Grid search trainieren ...\")\n",
    "  grid_search.fit(datasets['X_train'], datasets['y_train'])\n",
    "\n",
    "  print(\"Best params:\")\n",
    "  print(grid_search.best_params_)\n",
    "    \n",
    "  print(\"Ergebnis mit der besten Parametereinstellung auf den Trainingsdaten:\")\n",
    "  print(f\"{grid_search.best_score_:.3f}\")\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmale optimieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6: Einkommen und Alter diskretisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie jeweils einen Transformer um die Werte der Merkmale Einkommen und Alter zu diskretisieren. Verwenden Sie folgende Einstellungen:\n",
    "\n",
    "* Bin-Grenzwerte für das Einkommen: [0, 30000, 60000, 75000, 100000, 150000, 200000]  \n",
    "* Bin-Grenzwerte für das Alter: [0, 20, 30, 40, 60, 70, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Tip}\n",
    "* Sie können sich bei der Implementierung am AgeBinned Transformer aus dem Abschnitt Merkmale Optimieren orientieren.\n",
    "* Das Merkmal Einkommen steht im Pandas Dataframe in der ersten Spalte, der Index beträgt demzufolge 0.  \n",
    "* Das Merkmal Alter steht im Panas Dataframe in der zweiten Spalte, der Index beträgt demzufolge 1.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 6\n",
    "\n",
    "  ```{code-block} python\n",
    "  from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "  income_ix, age_ix = 0, 1\n",
    "  \n",
    "  class IncomeBinned(BaseEstimator, TransformerMixin):\n",
    "      def __init__(self):\n",
    "          pass\n",
    "\n",
    "      def fit(self, X, y=None):\n",
    "          return self\n",
    "\n",
    "      def transform(self, X, y=None):\n",
    "          X_ = pd.DataFrame(X)\n",
    "          bins = [0, 30000, 60000, 75000, 100000, 150000, 200000]\n",
    "          labels = [1,2,3,4,5,6]\n",
    "          X_[income_ix] = pd.cut(X_[income_ix], bins=bins, labels=labels)\n",
    "          return X_.values\n",
    "\n",
    "  class AgeBinned(BaseEstimator, TransformerMixin):\n",
    "      def __init__(self):\n",
    "          pass\n",
    "\n",
    "      def fit(self, X, y=None):\n",
    "          return self\n",
    "\n",
    "      def transform(self, X, y=None):\n",
    "          X_ = pd.DataFrame(X)\n",
    "          bins = [0, 20, 30, 40, 60, 70, 100]\n",
    "          labels = [1,2,3,4,5,6]\n",
    "          X_[age_ix] = pd.cut(X_[age_ix], bins=bins, labels=labels)\n",
    "          return X_.values\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7: Transformationen hinzufügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Übernehmen Sie die optimalen Parameter für folgende Parameter aus Task 5  \n",
    "* factor des OutlierRemoverExtended-Transformer\n",
    "* min_samples_split des Prediktors\n",
    "\n",
    "Fügen Sie drei Schritte in die numerische Pipeline ein:\n",
    "1. IncomeBinned-Transformer\n",
    "2. AgeBinned-Transformer\n",
    "3. StandardScaler-Transformer (von Scikit-learn)\n",
    "\n",
    "Kopieren Sie hierzu den Code aus der Vorlage und passen Sie die markierten Stellen <mark>[?]</mark> an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fügen Sie den Code aus der Vorlage hier ein und ergänzen Sie die mit [?] markierten Stellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Code Vorlage 7\n",
    "\n",
    "  ```{code-block} python\n",
    "  :emphasize-lines: 9,10,11,12,51\n",
    "  \n",
    "  from transformer_extended import OutlierRemoverExtended\n",
    "  from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "  from sklearn.pipeline import Pipeline\n",
    "  from sklearn.compose import ColumnTransformer\n",
    "  from transformer import OutlierRemover\n",
    "\n",
    "  # Pipeline für numerische Daten erstellen\n",
    "  pipeline_numerical = Pipeline(steps=[\n",
    "    ('outlier_remover', OutlierRemoverExtended(factor=[?])),\n",
    "    [?],\n",
    "    [?],\n",
    "    [?]\n",
    "  ])\n",
    "\n",
    "  # Pipeline für kategorische Daten erstellen\n",
    "  pipeline_categorical = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "  ])\n",
    "\n",
    "  features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "  features_categorical = [\n",
    "    'Marital Status', \n",
    "    'Gender', \n",
    "    'Education', \n",
    "    'Occupation', \n",
    "    'Home Owner', \n",
    "    'Commute Distance',\n",
    "    'Region'\n",
    "  ]\n",
    "\n",
    "  # Pipelines koordinieren\n",
    "  transformer_pipeline = ColumnTransformer(\n",
    "    transformers = [\n",
    "      (\n",
    "        'num', \n",
    "        pipeline_numerical,\n",
    "        features_numerical\n",
    "      ),\n",
    "      (\n",
    "        'cat', \n",
    "        pipeline_categorical,\n",
    "        features_categorical\n",
    "      )\n",
    "    ])\n",
    "\n",
    "\n",
    "  full_pipeline_fe1 = Pipeline(steps=[\n",
    "      ('transformers', transformer_pipeline),\n",
    "      ('predictor', DecisionTreeClassifier(\n",
    "        random_state=0,\n",
    "        min_samples_split=[?]\n",
    "      ))\n",
    "  ])\n",
    "\n",
    "  # Trainieren der Pipeline\n",
    "  full_pipeline_fe1.fit(datasets['X_train'], datasets['y_train'])\n",
    "  \n",
    "  # Ergebnis abfragen\n",
    "  print(\"Accuracy-Score nach Hinzufügen der Transformationen:\")\n",
    "  full_pipeline_fe1.score(datasets['X_val'], datasets['y_val'])\n",
    "    \n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 7\n",
    "\n",
    "  ```{code-block} python\n",
    "  :emphasize-lines: 10,11,12,50,51\n",
    "  \n",
    "  from transformer_extended import OutlierRemoverExtended\n",
    "  from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "  from sklearn.pipeline import Pipeline\n",
    "  from sklearn.compose import ColumnTransformer\n",
    "  from transformer import OutlierRemover\n",
    "\n",
    "  # Pipeline für numerische Daten erstellen\n",
    "  pipeline_numerical = Pipeline(steps=[\n",
    "    ('outlier_remover', OutlierRemoverExtended(factor=1.0)),\n",
    "    ('agebinned', AgeBinned()),\n",
    "    ('incomebinned', IncomeBinned()),\n",
    "    ('scaler', StandardScaler())\n",
    "  ])\n",
    "\n",
    "  # Pipeline für kategorische Daten erstellen\n",
    "  pipeline_categorical = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "  ])\n",
    "\n",
    "  # Numerische und Kategorische Merkmale definieren\n",
    "  features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "  features_categorical = [\n",
    "    'Marital Status', \n",
    "    'Gender', \n",
    "    'Education', \n",
    "    'Occupation', \n",
    "    'Home Owner', \n",
    "    'Commute Distance',\n",
    "    'Region'\n",
    "  ]\n",
    "\n",
    "  # Pipelines koordinieren\n",
    "  transformer_pipeline = ColumnTransformer(\n",
    "    transformers = [\n",
    "      (\n",
    "        'num', \n",
    "        pipeline_numerical,\n",
    "        features_numerical\n",
    "      ),\n",
    "      (\n",
    "        'cat', \n",
    "        pipeline_categorical,\n",
    "        features_categorical\n",
    "      )\n",
    "    ])\n",
    "\n",
    "  # Vollständige Pipeline erstellen\n",
    "  full_pipeline_fe1 = Pipeline(steps=[\n",
    "      ('transformers', transformer_pipeline),\n",
    "      ('predictor', DecisionTreeClassifier(\n",
    "        random_state=0,\n",
    "        min_samples_split=4\n",
    "      ))\n",
    "  ])\n",
    "\n",
    "  # Trainieren der Pipeline\n",
    "  full_pipeline_fe1.fit(datasets['X_train'], datasets['y_train'])\n",
    "  \n",
    "  # Ergebnis abfragen\n",
    "  print(\"Accuracy-Score nach Hinzufügen der Transformationen:\")\n",
    "  full_pipeline_fe1.score(datasets['X_val'], datasets['y_val'])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: Testen der optimierten Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Testen Sie die optimierte Pipeline aus Task 7 mit dem Testdatenset.\n",
    "2. Vergleichen Sie das Ergebnis mit dem Ergebnis aus Task 7.\n",
    "3. Vergleichen Sie das Ergebnis mit dem Ergebnis aus Task 3 (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 8\n",
    "\n",
    "  ```{code-block} python\n",
    "  # Erste Code-Zelle\n",
    "  full_pipeline_fe1.score(datasets['X_val'], datasets['y_val'])\n",
    "  \n",
    "  # Zweite Code-Zelle\n",
    "  full_pipeline_fe1.score(datasets['X_test'], datasets['y_test'])\n",
    "  ```\n",
    "  \n",
    "  1. Der Accuracy-Score beträgt 0.69\n",
    "  2. Das Ergebnis hat sich nicht verändert. Es zeigt, dass die Pipeline gut generalisiert.\n",
    "  3. Das Ergebnis hat sich um 0.1 verbessert. Die Verbesserung gegenüber der Baseline ist signifikant.\n",
    "  \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9: Optimierte Pipeline speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern Sie die optimierte Pipeline in einer Pickle-Datei unter '../output/bikebuyers/pipeline.pkl'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 9\n",
    "\n",
    "  ```{code-block} python\n",
    "  with open('../output/bikebuyers/pipeline.pkl', 'wb') as handle:\n",
    "    pickle.dump(full_pipeline_fe1, handle)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lösungen Teil 3: Parameter und Merkmale optimieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Zelle zum testen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösungen kompakt\n",
    "\n",
    "  ```{code-block} python\n",
    "  import pickle\n",
    "  from sklearn.pipeline import Pipeline\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "  with open('../output/bikebuyers/datasets.pkl', 'rb') as handle:\n",
    "      datasets = pickle.load(handle)\n",
    "  print('Dataset geladen')\n",
    "\n",
    "  with open('../output/bikebuyers/transformer_pipeline.pkl', 'rb') as handle:\n",
    "      transformer_pipeline = pickle.load(handle)\n",
    "\n",
    "  full_pipeline = Pipeline(steps=[\n",
    "      ('transformers', transformer_pipeline),\n",
    "      ('predictor', DecisionTreeClassifier(random_state=0))\n",
    "  ])\n",
    "\n",
    "  param_grid = {\n",
    "      'transformers__num__outlier_remover__factor': [1.0, 1.5, 2.0, 3.0],\n",
    "      'predictor__min_samples_split': [2,3,4,5,6],\n",
    "  }\n",
    "\n",
    "  grid_search = GridSearchCV(full_pipeline, param_grid, cv=10)\n",
    "  grid_search.fit(datasets['X_train'], datasets['y_train'])\n",
    "\n",
    "  print(\"\\nBest params:\")\n",
    "  print(grid_search.best_params_)\n",
    "\n",
    "  print(\"\\nErgebnis mit der besten Parametereinstellung auf den Trainingsdaten:\")\n",
    "  print(f\"{grid_search.best_score_:.3f}\")\n",
    "\n",
    "  best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "  with open('../output/bikebuyers/full_pipeline.pkl', 'wb') as handle:\n",
    "      pickle.dump(best_pipeline, handle)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Zelle zum testen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösungen kompakt\n",
    "\n",
    "  ```{code-block} python\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "  age_ix = 1\n",
    "  income_ix = 0\n",
    "\n",
    "  class AgeBinned(BaseEstimator, TransformerMixin):\n",
    "      def __init__(self):\n",
    "          pass\n",
    "\n",
    "      def fit(self, X, y=None):\n",
    "          return self\n",
    "\n",
    "      def transform(self, X, y=None):\n",
    "          X_ = pd.DataFrame(X)\n",
    "          bins = [0, 20, 30, 40, 60, 70, 100]\n",
    "          labels = [1,2,3,4,5,6]\n",
    "          X_[age_ix] = pd.cut(X_[age_ix], bins=bins, labels=labels)\n",
    "          return X_.values\n",
    "\n",
    "  class IncomeBinned(BaseEstimator, TransformerMixin):\n",
    "      def __init__(self):\n",
    "          pass\n",
    "\n",
    "      def fit(self, X, y=None):\n",
    "          return self\n",
    "\n",
    "      def transform(self, X, y=None):\n",
    "          X_ = pd.DataFrame(X)\n",
    "          bins = [0, 30000, 60000, 75000, 100000, 150000, 200000]\n",
    "          labels = [1,2,3,4,5,6]\n",
    "          X_[income_ix] = pd.cut(X_[income_ix], bins=bins, labels=labels)\n",
    "          return X_.values\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Zelle zum testen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösungen kompakt\n",
    "\n",
    "  ```{code-block} python\n",
    "  from transformer_extended import OutlierRemoverExtended\n",
    "  from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "  from sklearn.pipeline import Pipeline\n",
    "  from sklearn.compose import ColumnTransformer\n",
    "  from transformer import OutlierRemover\n",
    "\n",
    "  # Pipeline für numerische Daten erstellen\n",
    "  pipeline_numerical = Pipeline(steps=[\n",
    "    ('outlier_remover', OutlierRemoverExtended(factor=1.0)),\n",
    "    ('agebinned', AgeBinned()),\n",
    "    ('incomebinned', IncomeBinned()),\n",
    "    ('scaler', StandardScaler())\n",
    "  ])\n",
    "\n",
    "  # Pipeline für kategorische Daten erstellen\n",
    "  pipeline_categorical = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "  ])\n",
    "\n",
    "  features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "  features_categorical = [\n",
    "    'Marital Status', \n",
    "    'Gender', \n",
    "    'Education', \n",
    "    'Occupation', \n",
    "    'Home Owner', \n",
    "    'Commute Distance',\n",
    "    'Region'\n",
    "  ]\n",
    "\n",
    "  # Pipelines koordinieren\n",
    "  transformer_pipeline = ColumnTransformer(\n",
    "    transformers = [\n",
    "      (\n",
    "        'num', \n",
    "        pipeline_numerical,\n",
    "        features_numerical\n",
    "      ),\n",
    "      (\n",
    "        'cat', \n",
    "        pipeline_categorical,\n",
    "        features_categorical\n",
    "      )\n",
    "    ])\n",
    "\n",
    "\n",
    "  full_pipeline_fe1 = Pipeline(steps=[\n",
    "      ('transformers', transformer_pipeline),\n",
    "      ('predictor', DecisionTreeClassifier(\n",
    "        random_state=0,\n",
    "        min_samples_split=4\n",
    "      ))\n",
    "  ])\n",
    "\n",
    "  full_pipeline_fe1.fit(datasets['X_train'], datasets['y_train'])\n",
    "  full_pipeline_fe1.score(datasets['X_val'], datasets['y_val'])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensets geladen.\n",
      "Transformer Pipeline geladen.\n",
      "\n",
      "Best params:\n",
      "{'predictor__min_samples_split': 4, 'transformers__num__outlier_remover__factor': 1.0}\n",
      "\n",
      "\n",
      "Ergebnis mit der besten Parametereinstellung auf den Trainingsdaten:\n",
      "0.633\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "with open('../output/bikebuyers/datasets.pkl', 'rb') as handle:\n",
    "    datasets = pickle.load(handle)\n",
    "print('Datensets geladen.')\n",
    "\n",
    "with open('../output/bikebuyers/transformer_pipeline.pkl', 'rb') as handle:\n",
    "    transformer_pipeline = pickle.load(handle)\n",
    "print('Transformer Pipeline geladen.')\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('transformers', transformer_pipeline),\n",
    "    ('predictor', DecisionTreeClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'transformers__num__outlier_remover__factor': [1.0, 1.5, 2.0, 3.0],\n",
    "    'predictor__min_samples_split': [2,3,4,5,6],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=10)\n",
    "grid_search.fit(datasets['X_train'], datasets['y_train'])\n",
    "\n",
    "print(\"\\nBest params:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nErgebnis mit der besten Parametereinstellung auf den Trainingsdaten:\")\n",
    "print(f\"{grid_search.best_score_:.3f}\")\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "with open('../output/bikebuyers/full_pipeline.pkl', 'wb') as handle:\n",
    "    pickle.dump(best_pipeline, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "age_ix = 1\n",
    "income_ix = 0\n",
    "\n",
    "class AgeBinned(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = pd.DataFrame(X)\n",
    "        bins = [0, 20, 30, 40, 60, 70, 100]\n",
    "        labels = [1,2,3,4,5,6]\n",
    "        X_[age_ix] = pd.cut(X_[age_ix], bins=bins, labels=labels)\n",
    "        return X_.values\n",
    "      \n",
    "class IncomeBinned(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = pd.DataFrame(X)\n",
    "        bins = [0, 30000, 60000, 75000, 100000, 150000, 200000]\n",
    "        labels = [1,2,3,4,5,6]\n",
    "        X_[income_ix] = pd.cut(X_[income_ix], bins=bins, labels=labels)\n",
    "        return X_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from transformer_extended import OutlierRemoverExtended\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from transformer import OutlierRemover\n",
    "\n",
    "# Pipeline für numerische Daten erstellen\n",
    "pipeline_numerical = Pipeline(steps=[\n",
    "  ('outlier_remover', OutlierRemoverExtended(factor=1.0)),\n",
    "  ('agebinned', AgeBinned()),\n",
    "  ('incomebinned', IncomeBinned()),\n",
    "  ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline für kategorische Daten erstellen\n",
    "pipeline_categorical = Pipeline(steps=[\n",
    "  ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "features_categorical = [\n",
    "  'Marital Status', \n",
    "  'Gender', \n",
    "  'Education', \n",
    "  'Occupation', \n",
    "  'Home Owner', \n",
    "  'Commute Distance',\n",
    "  'Region'\n",
    "]\n",
    "\n",
    "# Pipelines koordinieren\n",
    "transformer_pipeline = ColumnTransformer(\n",
    "  transformers = [\n",
    "    (\n",
    "      'num', \n",
    "      pipeline_numerical,\n",
    "      features_numerical\n",
    "    ),\n",
    "    (\n",
    "      'cat', \n",
    "      pipeline_categorical,\n",
    "      features_categorical\n",
    "    )\n",
    "  ])\n",
    "\n",
    "\n",
    "full_pipeline_fe1 = Pipeline(steps=[\n",
    "    ('transformers', transformer_pipeline),\n",
    "    ('predictor', DecisionTreeClassifier(\n",
    "      random_state=0,\n",
    "      min_samples_split=4\n",
    "    ))\n",
    "])\n",
    "\n",
    "full_pipeline_fe1.fit(datasets['X_train'], datasets['y_train'])\n",
    "full_pipeline_fe1.score(datasets['X_val'], datasets['y_val'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
