{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell",
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/alandmesser/anaconda3/envs/workshops/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pakete importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packete importiert.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('Pakete importiert.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerische Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Einlesen der Datensets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesen Sie die gespeicherten Datensets aus der pickle-Datei '../output/bikebuyers/datasets.pkl' aus und geben Sie die ersten fünf Zeilen der Merkmale im Trainingsdatenset (X_train) aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geben Sie die ersten fünf Zeilen der Zielgrößen im Trainingsdatenset (y_train) aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 1\n",
    "\n",
    "  ```{code-block} python\n",
    "  # Erste Code-Zelle\n",
    "  with open('../output/bikebuyers/datasets.pkl', 'rb') as handle:      \n",
    "    datasets = pickle.load(handle)\n",
    "        \n",
    "  datasets['X_train'].head()\n",
    "    \n",
    "  # Zweite Code-Zelle\n",
    "  datasets['y_train'].head()\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Ausreißer erkennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermitteln Sie mit der IQR-Methode die Ausreißer, ersetzen diese mit dem NaN-Wert (np.nan) und geben Sie die Anzahl der Ausreißer pro Merkmal aus. Verwenden Sie den Faktor 1.5 bei der IQR-Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ersetzen Sie die NaN-Werte mit dem Mittelwert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Tip}\n",
    "Schritte zur Lösung:\n",
    "* Eine Variable factor erstellen und mit dem Wert 1.5 belegen.\n",
    "* Mit Hilfe der [quantile()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html)-Methode das 25%-Quantil bestimmen und in einer Variable q1 speichern.\n",
    "* Mit Hilfe der [quantile()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html)-Methode das 75%-Quantil bestimmen und in einer Variable q3 speichern.\n",
    "* Die Differenz von q3 und q1 berechnen und in einer Variable namens iqr speichern.\n",
    "* Die Untere Grenze berechnen durch die Differenz von q1 und dem Faktor multipliziert mit iqr.\n",
    "* Alle Werte die außerhalb des Bereichs liegen (definierte Grenzen) mit dem NaN-Wert belegen.\n",
    "* Mit Hilfe der Methode [isna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html) alle NaN-Werte identifizieren und mit Hilfe der Methode sum() die Anzahl pro Merkmal ausgeben.\n",
    "* Die Methode [fillna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) hilft bei dem Ersetzen der NaN-Werte.\n",
    "* Die [mean()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.mean.html)-Methode ermittelt Mittelwerte eines DataFrames.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 2\n",
    "\n",
    "  ```{code-block} python\n",
    "  # Erste Code-Zelle\n",
    "  X_ = pd.DataFrame(datasets['X_train'])\n",
    "  factor = 1.5\n",
    "  q1 = X_.quantile(0.25)\n",
    "  q3 = X_.quantile(0.75)\n",
    "  iqr = q3 - q1\n",
    "  lower_bound = q1 - (factor * iqr)\n",
    "  upper_bound = q3 + (factor * iqr)\n",
    "  X_[((X_ < lower_bound) | (X_ > upper_bound))] = np.nan\n",
    "  X_.isna().sum()\n",
    "\n",
    "  # Zweite‚ Code-Zelle\n",
    "  X_.fillna(X_.mean(), inplace=True)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Outlier Remover Transformer erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Klasse \"OutlierRemoverExtended\", welche das Transformer-Interface von Scikit Learn abbildet und von den Klassen BaseEstimator und TranformerMixin ableitet. Speichern Sie die Klasse in einer Datei namens \"transformer_extended.py\" mit Hilfe des [%%writefile](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-writefile) Befehls. Bei der Instanziierung der Klasse sollen zwei Parameter gesetzt werden können:\n",
    "* factor, Default-Wert 1.5\n",
    "* strategy, Default-Wert 'median'\n",
    "\n",
    "Die fit()-Methode soll zwei numpy-Arrays als Parameter (X und y), keine Funktion enthalten und nur die Instanz selbst zurückgeben. Die Transformer-Methode soll die gleichen Parameter wie die fit()-Methode erhalten, Ausreißer mit der IQR-Methode unter Verwendung des factor-Paramters erkennen und mit dem Mittelwert oder dem Median ersetzen. Welche Art zum Einsatz kommt, wird mit dem Paramter strategy bestimmt. Valide Werte sind 'median' und 'mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 3\n",
    "\n",
    "  ```{code-block} python\n",
    "  %%writefile transformer_extended.py\n",
    "  \n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  from sklearn.base import BaseEstimator, TransformerMixin\n",
    "  \n",
    "  class OutlierRemoverExtended(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5, strategy='median'):\n",
    "      self.factor = factor\n",
    "      self.strategy = strategy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "      return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "      X_ = pd.DataFrame(X)\n",
    "      q1 = X_.quantile(0.25)\n",
    "      q3 = X_.quantile(0.75)\n",
    "      iqr = q3 - q1\n",
    "      lower_bound = q1 - (self.factor * iqr)\n",
    "      upper_bound = q3 + (self.factor * iqr)\n",
    "      X_[((X_ < lower_bound) | (X_ > upper_bound))] = np.nan\n",
    "\n",
    "      if self.strategy == 'median':\n",
    "        X_.fillna(X_.median(), inplace=True)\n",
    "      elif self.strategy == 'mean':\n",
    "        X_.fillna(X_.mean(), inplace=True)\n",
    "      else:\n",
    "        raise ValueError('Invalid value for strategy paramter. Valid values are median or mean.')\n",
    "\n",
    "      return X_.values\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Transformer anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Erstellen Sie eine Instanz der Klasse OutlierRemoverExtended.\n",
    "* Wenden Sie die fit_transform()-Methode auf das Trainingsdatenset an und speichern das Ergebnis in einer Variable.\n",
    "* Erstellen Sie ein Pandas DataFrame, übergeben sie dabei die transformierten Werte und geben das Ergebnis aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 4\n",
    "\n",
    "  ```{code-block} python\n",
    "  from transformer_extended import OutlierRemoverExtended\n",
    "  \n",
    "  outlier_remover = OutlierRemoverExtended()\n",
    "  res = outlier_remover.fit_transform(datasets['X_train'])\n",
    "  pd.DataFrame(res)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Pipeline für numerische Daten erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Pipeline mit Hilfe der [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)-Klasse von Scikit Learn. Schritte der Pipeline:\n",
    "1. Der OutlierRemoverExtended-Transformer aus Task 3  \n",
    "2. [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) von Scikit Learn\n",
    "\n",
    "Speichern Sie die Pipeline in einer Variable namens pipeline_numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 5\n",
    "\n",
    "  ```{code-block} python\n",
    "  from sklearn.pipeline import Pipeline\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "  pipeline_numerical = Pipeline(steps=[\n",
    "    ('outlier_remover', OutlierRemoverExtended()),\n",
    "    ('scaler', StandardScaler())\n",
    "  ])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kategorische Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Pipeline für kategorische Daten erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie eine Pipeline mit Hilfe der [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)-Klasse von Scikit Learn. Schritte der Pipeline:\n",
    "1. [OneHot-Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) von Scikit Learn  \n",
    "\n",
    "Speichern Sie die Pipeline in einer Variable namens pipeline_categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 6\n",
    "\n",
    "  ```{code-block} python\n",
    "  from sklearn.pipeline import Pipeline\n",
    "  from sklearn.preprocessing import OneHotEncoder\n",
    "  \n",
    "  pipeline_categorical = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "  ])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformationen koordinieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Pipelines zusammenfügen und Merkmale zuweisen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bezeichnungen der numerischen Features in einer Liste mit Elementen vom Typ String namens 'features_numerical' speichern.\n",
    "* Bezeichnungen der kategorischen Features in einer Liste mit Elmenten vom Typ String namens 'features_categorical' speichern.\n",
    "* Eine Instanz des [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) aus Scikit Learn erstellen. Dabei dem Parameter transformers die Tuples \n",
    "    * ('num', pipeline_numerical, features_numerical)\n",
    "    * ('cat', pipeline_categorical, features_categorical)  \n",
    "übergeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 7\n",
    "\n",
    "  ```{code-block} python\n",
    "  from sklearn.compose import ColumnTransformer\n",
    "\n",
    "  features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "  features_categorical = [\n",
    "    'Marital Status', \n",
    "    'Gender', \n",
    "    'Education', \n",
    "    'Occupation', \n",
    "    'Home Owner', \n",
    "    'Commute Distance',\n",
    "    'Region'\n",
    "  ]\n",
    "\n",
    "  transformer_pipeline = ColumnTransformer(\n",
    "    transformers = [\n",
    "      (\n",
    "        'num', \n",
    "        pipeline_numerical,\n",
    "        features_numerical\n",
    "      ),\n",
    "      (\n",
    "        'cat', \n",
    "        pipeline_categorical,\n",
    "        features_categorical\n",
    "      )\n",
    "    ])\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Transformer-Pipeline anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die Transformer Pipeline auf dem Trainingsdatenset(X_train) anwenden durch aufrufen der Methode fit_transform() und speichern des Rückgabewert vom Typ Numpy-Array in einer Variable namens 'res'.\n",
    "* Aus dem Numpy-Array res ein Pandas DataFrame erstellen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 8\n",
    "\n",
    "  ```{code-block} python\n",
    "  res = transformer_pipeline.fit_transform(datasets['X_train'])\n",
    "  pd.DataFrame(res)\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Merkmalsbezeichnungen hinzufügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die neuen Feature-Bezeichnungen aus der Transformer Pipeline des Step 'onehot' über die Methode [get_feature_names()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) abfragen und in einer Variable namens feature_categorical_onehot speichern.\n",
    "* Aus dem Numpy-Array res und den Merkmalsbezeichnungen (feature_catgorical_onehot und features_numerical) ein Pandas DataFrame erstellen und ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 9\n",
    "\n",
    "  ```{code-block} python\n",
    "  feature_categorical_onehot = transformer_pipeline\\\n",
    "    .transformers_[1][1]['onehot']\\\n",
    "    .get_feature_names(features_categorical)\n",
    "\n",
    "  pd.DataFrame(res, columns=features_numerical+list(feature_categorical_onehot))\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Auf alle Datensets anwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenden Sie die Transformationen auf alle Datensets (Training, Validierung und Test) an und speichern das Ergebnis in den Variablen X_train_transformed, X_val_transformed und X_test_transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen Sie aus jedem transformierten Datenset ein Pandas Datenframe inklusive der Spaltenbezeichnungen und speichern diese in den gleichen Variablen. Die neuen Spaltenbezeichungen der kategorischen Daten können sie aus der Variable feature_categorical_onehot des vorherigen Tasks auslesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geben Sie die ersten Zeilen des Pandas Dataframe X_train_transformed aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 10\n",
    "\n",
    "  ```{code-block} python\n",
    "  # Erste Code-Zelle\n",
    "  X_train_transformed = transformer_pipeline.fit_transform(datasets['X_train'])\n",
    "  X_val_transformed = transformer_pipeline.transform(datasets['X_val'])\n",
    "  X_test_transformed = transformer_pipeline.transform(datasets['X_test'])\n",
    "\n",
    "  # Zweite Code-Zelle\n",
    "  X_train_transformed = pd.DataFrame(X_train_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "  X_val_transformed = pd.DataFrame(X_val_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "  X_test_transformed = pd.DataFrame(X_test_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "\n",
    "  # Dritte Code-Zelle\n",
    "  X_train_transformed.head()\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11: Transformierte Daten speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern Sie die transformierten Daten in einem Dictionary unter Verwendung der Keys \n",
    "* X_train\n",
    "* y_train\n",
    "* X_val\n",
    "* y_val\n",
    "* X_test\n",
    "* y_test  \n",
    "\n",
    "in einer Variable namens \"datasets_tranformed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern Sie die transformierten Daten in einer Pickle-Datei unter '../output/bikebuyers/datesets_transformed.pkl'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 11\n",
    "  \n",
    "  ```{code-block} python  \n",
    "  # Erste Code-Zelle\n",
    "  datasets_transformed = {\n",
    "      'X_train': X_train_transformed,\n",
    "      'y_train': datasets['y_train'],\n",
    "      'X_val': X_val_transformed,\n",
    "      'y_val': datasets['y_val'],\n",
    "      'X_test': X_test_transformed,\n",
    "      'y_test': datasets['y_test']\n",
    "  }\n",
    "  \n",
    "  # Zweite Code-Zelle\n",
    "  with open('../output/bikebuyers/datesets_transformed.pkl', 'wb') as handle:\n",
    "    pickle.dump(datasets_transformed, handle)\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: Pipeline speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern Sie die Pipeline mit der besten Parametereinstellung in einer Pickle-Datei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier den Code eingeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösung Task 12\n",
    "\n",
    "  ```{code-block} python\n",
    "  with open('../output/bikebuyers/transformer_pipeline.pkl', 'wb') as handle:\n",
    "    pickle.dump(transformer_pipeline, handle)\n",
    "\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lösungen Teil 2: Pipelines erstellen, koordinieren und anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Zelle zum testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösungen kompakt - Outlier Remover Extended\n",
    "\n",
    "  ```{code-block} python\n",
    "  %%writefile transformer_extended.py\n",
    "  \n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  from sklearn.base import BaseEstimator, TransformerMixin\n",
    "  \n",
    "  class OutlierRemoverExtended(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5, strategy='median'):\n",
    "      self.factor = factor\n",
    "      self.strategy = strategy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "      return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "      X_ = pd.DataFrame(X)\n",
    "      q1 = X_.quantile(0.25)\n",
    "      q3 = X_.quantile(0.75)\n",
    "      iqr = q3 - q1\n",
    "      lower_bound = q1 - (self.factor * iqr)\n",
    "      upper_bound = q3 + (self.factor * iqr)\n",
    "      X_[((X_ < lower_bound) | (X_ > upper_bound))] = np.nan\n",
    "\n",
    "      if self.strategy == 'median':\n",
    "        X_.fillna(X_.median(), inplace=True)\n",
    "      elif self.strategy == 'mean':\n",
    "        X_.fillna(X_.mean(), inplace=True)\n",
    "      else:\n",
    "        raise ValueError('Invalid value for strategy paramter. Valid values are median or mean.')\n",
    "\n",
    "      return X_.values\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Zelle zum testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{Dropdown} Lösungen kompakt - Pipelines\n",
    "\n",
    "  ```{code-block} python\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "  import sklearn as sklearn\n",
    "  import pickle\n",
    "  \n",
    "  from transformer_extended import OutlierRemoverExtended\n",
    "  from sklearn.pipeline import Pipeline\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  from sklearn.preprocessing import OneHotEncoder\n",
    "  from sklearn.compose import ColumnTransformer\n",
    "  \n",
    "  # Datensets einlesen\n",
    "  with open('../output/bikebuyers/datasets.pkl', 'rb') as handle:      \n",
    "    datasets = pickle.load(handle)\n",
    "  \n",
    "  # Outlier Remover erstellen\n",
    "  outlier_remover = OutlierRemoverExtended()\n",
    "  res = outlier_remover.fit_transform(datasets['X_train'])\n",
    "  pd.DataFrame(res)\n",
    "  \n",
    "  # Pipeline für numerische Daten erstellen\n",
    "  pipeline_numerical = Pipeline(steps=[\n",
    "    ('outlier_remover', OutlierRemoverExtended()),\n",
    "    ('scaler', StandardScaler())\n",
    "  ])\n",
    "  \n",
    "  # Pipeline für kategorische Daten erstellen\n",
    "  pipeline_categorical = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "  ])\n",
    "\n",
    "  features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "  features_categorical = [\n",
    "    'Marital Status', \n",
    "    'Gender', \n",
    "    'Education', \n",
    "    'Occupation', \n",
    "    'Home Owner', \n",
    "    'Commute Distance',\n",
    "    'Region'\n",
    "  ]\n",
    "\n",
    "  # Pipelines koordinieren\n",
    "  transformer_pipeline = ColumnTransformer(\n",
    "    transformers = [\n",
    "      (\n",
    "        'num', \n",
    "        pipeline_numerical,\n",
    "        features_numerical\n",
    "      ),\n",
    "      (\n",
    "        'cat', \n",
    "        pipeline_categorical,\n",
    "        features_categorical\n",
    "      )\n",
    "    ])\n",
    "  \n",
    "  # Transformationen auf alle Datensets anwenden\n",
    "  X_train_transformed = transformer_pipeline.fit_transform(datasets['X_train'])\n",
    "  X_val_transformed = transformer_pipeline.transform(datasets['X_val'])\n",
    "  X_test_transformed = transformer_pipeline.transform(datasets['X_test'])\n",
    "  \n",
    "  feature_categorical_onehot = transformer_pipeline\\\n",
    "    .transformers_[1][1]['onehot']\\\n",
    "    .get_feature_names(features_categorical)\n",
    "\n",
    "  X_train_transformed = pd.DataFrame(X_train_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "  X_val_transformed = pd.DataFrame(X_val_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "  X_test_transformed = pd.DataFrame(X_test_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "  \n",
    "  # Transformierte Datensets speichern\n",
    "  datasets_transformed = {\n",
    "      'X_train': X_train_transformed,\n",
    "      'y_train': datasets['y_train'],\n",
    "      'X_val': X_val_transformed,\n",
    "      'y_val': datasets['y_val'],\n",
    "      'X_test': X_test_transformed,\n",
    "      'y_test': datasets['y_test']\n",
    "  }\n",
    "  \n",
    "  with open('../output/bikebuyers/datesets_transformed.pkl', 'wb') as handle:\n",
    "    pickle.dump(datasets_transformed, handle)\n",
    "    \n",
    "  # Pipeline speichern\n",
    "  with open('../output/bikebuyers/transformer_pipeline.pkl', 'wb') as handle:\n",
    "    pickle.dump(transformer_pipeline, handle)\n",
    "  \n",
    "  # Ergebnis anzeigen\n",
    "  print('Erste 5 Zeilen des transformierten Trainingsdatenset')\n",
    "  datasets_transformed['X_train'].head()\n",
    "  ```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transformer_extended.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transformer_extended.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class OutlierRemoverExtended(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, factor=1.5, strategy='median'):\n",
    "    self.factor = factor\n",
    "    self.strategy = strategy\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "\n",
    "  def transform(self, X, y=None):\n",
    "    X_ = pd.DataFrame(X)\n",
    "    q1 = X_.quantile(0.25)\n",
    "    q3 = X_.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (self.factor * iqr)\n",
    "    upper_bound = q3 + (self.factor * iqr)\n",
    "    X_[((X_ < lower_bound) | (X_ > upper_bound))] = np.nan\n",
    "\n",
    "    if self.strategy == 'median':\n",
    "      X_.fillna(X_.median(), inplace=True)\n",
    "    elif self.strategy == 'mean':\n",
    "      X_.fillna(X_.mean(), inplace=True)\n",
    "    else:\n",
    "      raise ValueError('Invalid value for strategy paramter. Valid values are median or mean.')\n",
    "\n",
    "    return X_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erste 5 Zeilen des transformierten Trainingsdatenset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Children</th>\n",
       "      <th>Marital Status_Married</th>\n",
       "      <th>Marital Status_Single</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Graduate Degree</th>\n",
       "      <th>...</th>\n",
       "      <th>Home Owner_No</th>\n",
       "      <th>Home Owner_Yes</th>\n",
       "      <th>Commute Distance_0-1 Miles</th>\n",
       "      <th>Commute Distance_1-2 Miles</th>\n",
       "      <th>Commute Distance_10+ Miles</th>\n",
       "      <th>Commute Distance_2-5 Miles</th>\n",
       "      <th>Commute Distance_5-10 Miles</th>\n",
       "      <th>Region_Europe</th>\n",
       "      <th>Region_North America</th>\n",
       "      <th>Region_Pacific</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868704</td>\n",
       "      <td>-0.902227</td>\n",
       "      <td>-0.303318</td>\n",
       "      <td>-1.178359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.507704</td>\n",
       "      <td>-0.625753</td>\n",
       "      <td>-1.380188</td>\n",
       "      <td>-1.178359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.524602</td>\n",
       "      <td>1.309566</td>\n",
       "      <td>-0.303318</td>\n",
       "      <td>1.272301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.163602</td>\n",
       "      <td>-0.902227</td>\n",
       "      <td>-1.380188</td>\n",
       "      <td>-0.565694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.589215</td>\n",
       "      <td>2.138988</td>\n",
       "      <td>-0.303318</td>\n",
       "      <td>0.046971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income       Age      Cars  Children  Marital Status_Married  \\\n",
       "0  0.868704 -0.902227 -0.303318 -1.178359                     1.0   \n",
       "1 -0.507704 -0.625753 -1.380188 -1.178359                     1.0   \n",
       "2  0.524602  1.309566 -0.303318  1.272301                     1.0   \n",
       "3 -0.163602 -0.902227 -1.380188 -0.565694                     1.0   \n",
       "4  2.589215  2.138988 -0.303318  0.046971                     0.0   \n",
       "\n",
       "   Marital Status_Single  Gender_Female  Gender_Male  Education_Bachelors  \\\n",
       "0                    0.0            1.0          0.0                  1.0   \n",
       "1                    0.0            1.0          0.0                  0.0   \n",
       "2                    0.0            0.0          1.0                  1.0   \n",
       "3                    0.0            0.0          1.0                  1.0   \n",
       "4                    1.0            1.0          0.0                  1.0   \n",
       "\n",
       "   Education_Graduate Degree  ...  Home Owner_No  Home Owner_Yes  \\\n",
       "0                        0.0  ...            0.0             1.0   \n",
       "1                        1.0  ...            0.0             1.0   \n",
       "2                        0.0  ...            0.0             1.0   \n",
       "3                        0.0  ...            0.0             1.0   \n",
       "4                        0.0  ...            1.0             0.0   \n",
       "\n",
       "   Commute Distance_0-1 Miles  Commute Distance_1-2 Miles  \\\n",
       "0                         0.0                         1.0   \n",
       "1                         1.0                         0.0   \n",
       "2                         0.0                         1.0   \n",
       "3                         1.0                         0.0   \n",
       "4                         1.0                         0.0   \n",
       "\n",
       "   Commute Distance_10+ Miles  Commute Distance_2-5 Miles  \\\n",
       "0                         0.0                         0.0   \n",
       "1                         0.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   Commute Distance_5-10 Miles  Region_Europe  Region_North America  \\\n",
       "0                          0.0            0.0                   1.0   \n",
       "1                          0.0            1.0                   0.0   \n",
       "2                          0.0            0.0                   1.0   \n",
       "3                          0.0            0.0                   1.0   \n",
       "4                          0.0            0.0                   1.0   \n",
       "\n",
       "   Region_Pacific  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import pickle\n",
    "\n",
    "from transformer_extended import OutlierRemoverExtended\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Datensets einlesen\n",
    "with open('../output/bikebuyers/datasets.pkl', 'rb') as handle:      \n",
    "  datasets = pickle.load(handle)\n",
    "\n",
    "# Outlier Remover erstellen\n",
    "outlier_remover = OutlierRemoverExtended()\n",
    "res = outlier_remover.fit_transform(datasets['X_train'])\n",
    "pd.DataFrame(res)\n",
    "\n",
    "# Pipeline für numerische Daten erstellen\n",
    "pipeline_numerical = Pipeline(steps=[\n",
    "  ('outlier_remover', OutlierRemoverExtended()),\n",
    "  ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline für kategorische Daten erstellen\n",
    "pipeline_categorical = Pipeline(steps=[\n",
    "  ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "features_numerical = ['Income', 'Age', 'Cars', 'Children']\n",
    "features_categorical = [\n",
    "  'Marital Status', \n",
    "  'Gender', \n",
    "  'Education', \n",
    "  'Occupation', \n",
    "  'Home Owner', \n",
    "  'Commute Distance',\n",
    "  'Region'\n",
    "]\n",
    "\n",
    "# Pipelines koordinieren\n",
    "transformer_pipeline = ColumnTransformer(\n",
    "  transformers = [\n",
    "    (\n",
    "      'num', \n",
    "      pipeline_numerical,\n",
    "      features_numerical\n",
    "    ),\n",
    "    (\n",
    "      'cat', \n",
    "      pipeline_categorical,\n",
    "      features_categorical\n",
    "    )\n",
    "  ])\n",
    "\n",
    "# Transformationen auf alle Datensets anwenden\n",
    "X_train_transformed = transformer_pipeline.fit_transform(datasets['X_train'])\n",
    "X_val_transformed = transformer_pipeline.transform(datasets['X_val'])\n",
    "X_test_transformed = transformer_pipeline.transform(datasets['X_test'])\n",
    "\n",
    "feature_categorical_onehot = transformer_pipeline\\\n",
    "  .transformers_[1][1]['onehot']\\\n",
    "  .get_feature_names(features_categorical)\n",
    "\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "X_val_transformed = pd.DataFrame(X_val_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed, columns=features_numerical+list(feature_categorical_onehot))\n",
    "\n",
    "# Transformierte Datensets speichern\n",
    "datasets_transformed = {\n",
    "    'X_train': X_train_transformed,\n",
    "    'y_train': datasets['y_train'],\n",
    "    'X_val': X_val_transformed,\n",
    "    'y_val': datasets['y_val'],\n",
    "    'X_test': X_test_transformed,\n",
    "    'y_test': datasets['y_test']\n",
    "}\n",
    "\n",
    "with open('../output/bikebuyers/datesets_transformed.pkl', 'wb') as handle:\n",
    "  pickle.dump(datasets_transformed, handle)\n",
    "  \n",
    "# Pipeline speichern\n",
    "with open('../output/bikebuyers/transformer_pipeline.pkl', 'wb') as handle:\n",
    "  pickle.dump(transformer_pipeline, handle)\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print('Erste 5 Zeilen des transformierten Trainingsdatenset')\n",
    "datasets_transformed['X_train'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
